<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>利用GitHub Pages和Hexo搭建个人主页</title>
    <url>/2022/06/gitpage/</url>
    <content><![CDATA[<p>GitHub Pages是GitHub推出的一个用于快速搭建个人主页的方案，相较于自己买服务器建站，它免去了购买服务器域名的开销，而对于CSDN和博客园这种公开的社区，它没有广告充值VIP的操作(CSDN)，更像属于个人的网站。</p>
<blockquote>
<p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
</blockquote>
<p>简而言之，通过Hexo我们可以很快的从Markdown生成静态网页，相较于WordPress这种动态框架，更加安全也更容易管理，作为个人博客，Hexo绰绰有余。</p>
<span id="more"></span>
<h2 id="准备">准备</h2>
<h3 id="注册github账号">注册GitHub账号</h3>
<p>首先我们需要一个GitHub账号用于构建GitHub Pages。注册方式很简单，只需要进入GitHub的<a href="https://github.com/">官网</a>点击右上角的Sign up即可。</p>
<p>注册完成后，我们需要创建一个新仓库用于存放我们的个人主页。点击New repository，进行创建，仓库的名称应该是<code>你的GitHub用户名.http://github.io</code>这样的固定写法。</p>
<h3 id="安装git">安装Git</h3>
<p>到Git的<a href="https://git-scm.com/downloads">官网</a>下载对应的版本安装。</p>
<p>安装完成后打开终端进行配置，如果是Windows系统则右键打开Git Bash</p>
<img src="/2022/06/gitpage/gitbash.jpg" class="">
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;你的GitHub用户名&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;你的GitHub注册邮箱&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后生成ssh密钥文件：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;你的GitHub注册邮箱&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后直接三个回车即可，默认不需要设置密码 然后找到生成的.ssh的文件夹中的id_rsa.pub密钥，将内容全部复制，其中Linux下生成的密钥在~/.ssh文件夹中，Windows下在如图所示的目录下：</p>
<img src="/2022/06/gitpage/ssh_key.jpg" class="">
<p>打开<a href="https://github.com/settings/keys">GitHub_Settings_keys</a>页面，新建new SSH Key，Title为标题，任意填即可，将刚刚复制的id_rsa.pub内容粘贴进去，最后点击Add SSH key。</p>
<p>在终端中输入<code>ssh git@github.com</code>检测公钥是否设置成功，如果出现下图则代表设置成功。</p>
<img src="/2022/06/gitpage/key_success.jpg" class="">
<h3 id="安装node.js">安装Node.js</h3>
<p>Hexo基于Node.js，到<a href="https://nodejs.org/zh-cn/download/">官网</a>下载对应版本，安装完成后通过输入<code>node -v</code>检测安装是否成功。</p>
<h3 id="安装hexo">安装Hexo</h3>
<p>所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<h3 id="建站">建站</h3>
<p>在以上的准备工作完成后，我们就可以开始搭建自己的网站了。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo init 文件夹名称</span><br><span class="line"><span class="built_in">cd</span> 文件夹名称</span><br></pre></td></tr></table></figure>
<p>首先我们通过Hexo的init指令新建了一个项目的文件夹，然后切换到这个文件夹的目录下。完成后文件夹目录的结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── _config.yml</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── source</span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure>
<h3 id="文件说明">文件说明</h3>
<h4 id="config.yml">_config.yml</h4>
<p>这个文件存储了网站的基本配置信息。</p>
<h4 id="source">source</h4>
<p>这个文件夹存储了Markdown，以及图片等各种资源，我们编写好的Markdown文件会存储在这里，用于生成静态网页。</p>
<h4 id="themes">themes</h4>
<p>主题文件夹，将喜欢的主题放在这里，再更改_config.yml中的主题设置就能很方便的替换网站的主题。</p>
<h3 id="常用命令">常用命令</h3>
<h4 id="init">init</h4>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo init 文件夹名称</span><br></pre></td></tr></table></figure>
<p>上面我们使用过的命令，作用是新建一个网站，如果没有指定文件夹就会在当前目录建立。</p>
<h4 id="new">new</h4>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo new 文章名称</span><br></pre></td></tr></table></figure>
<p>new命令可以新建一篇文章，文章默认会在source/_posts位置下，如果文章的名称中包含空格，那么使用引号括起来。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;post title with whitespace&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="generate">generate</h4>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br></pre></td></tr></table></figure>
<p>生成静态文件，即把我们写的Markdown文件结合配置生成为网页文件。可以简写为<code>hexo g</code></p>
<h4 id="server">server</h4>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>在终端输入 <img src="/2022/06/gitpage/server.png" class=""></p>
<p>打开浏览器<a href="http://localhost:4000">http://localhost:4000</a>，就能看到网站 <img src="/2022/06/gitpage/browser.png" class=""></p>
<p>效果可能与图片中有所不同，这是因为我使用了别的主题做了一些其他的配置。这个命令也可以简写为<code>hexo s</code></p>
<h4 id="deploy">deploy</h4>
<p>部署网站。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<p>在进行配置后，我们可以通过这个命令将我们的网站推送到GitHub Page上，这样就可以被别人访问到了。这个命令可以简写为<code>hexo d</code></p>
<h2 id="部署">部署</h2>
<p>在进行部署前，我们要首先对网站配置文件_config.yml进行设置。打开_config.yml，拉到最下面，将deploy设置改为：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repo: git@github.com:你的GitHub用户名/你的GitHub用户名.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<p>配置完成后，我们在终端输入：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>
<p>然后等待推送过程完成，在推送完成后，我们直接打开GitHub Pages的个人网址就能访问我们搭建好的网站了。</p>
<h2 id="结语">结语</h2>
<p>这已经是我第四次搭建个人博客了，从最早的用Django练习Python搭建的博客到用WordPress搭的花里胡哨的博客，再到用Hexo搭建的上个博客，然后因为重装系统把博客的源文件删掉，导致没办法继续更新，只能重新搭建好了现在这个。希望这个博客能陪我久一些，自己也尽可能更新的快一些，不断的学习新的东西，记录到这个博客里面吧。</p>
<p>关于博客搭建的教程，之后会介绍关于博客的一些主题配置，第三方的插件的使用，敬请期待~</p>
<h2 id="参考">参考</h2>
<ol type="1">
<li><a href="https://hexo.io/zh-cn/docs/">Hexo官方文档</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/26625249">GitHub+Hexo 搭建个人网站详细教程</a></li>
</ol>
]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>GitHub Pages</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是Inductive Learning 和 Transductive Learning？</title>
    <url>/2022/09/transductive-learning/</url>
    <content><![CDATA[<p>一般所说的学习方式是指的Inductive Learning，将训练集<span class="math inline">\(X_{train}, y_{train}\)</span>和测试集<span class="math inline">\(X_{test}, y_{test}\)</span>划分开，而Transductive Learning在训练的过程中利用了<span class="math inline">\(X_{test}\)</span>的信息。</p>
<span id="more"></span>
<h2 id="优缺点对比">优缺点对比</h2>
<p>对于Inductive的方法而言，任何需要预测的数据都可以直接进行推导，因为在训练过程中也只用到了<span class="math inline">\(X_{train}\)</span>的数据，因此得到的模型是不需要改变的，但是缺陷是在数据增多之后也只能用到原来的数据</p>
<p>对于Transductive的方法，他们可以同时利用到<span class="math inline">\(X_{train}, y_{train}\)</span>和<span class="math inline">\(X_{test}\)</span>的特征，那么效果肯定优于Inductive的方法，但是每次有新的数据产生时，都会使得<span class="math inline">\(X_{test}\)</span>发生改变从而使得整个模型都需要重新进行训练。</p>
<h2 id="参考">参考</h2>
<ol type="1">
<li><a href="https://www.zhihu.com/question/68275921">知乎 - 如何理解 inductive learning 与 transductive learning?</a></li>
</ol>
]]></content>
      <tags>
        <tag>Inductive Learning</tag>
        <tag>Transductive Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯个性化排序BPR</title>
    <url>/2022/09/BPR/</url>
    <content><![CDATA[<p>贝叶斯个性化排序(BPR, Bayesian Personalized Ranking)是推荐系统中常用的一种推荐算法，它主要采用用户的隐式反馈(点击、收藏等)作为特征，通过对问题进行贝叶斯分析从而对item进行排序。 <span id="more"></span></p>
<h2 id="排序推荐算法分类">排序推荐算法分类</h2>
<p>排序推荐算法可以大致被分为三类：</p>
<ol type="1">
<li>点对方法(Pointwise Approach)，这类算法将排序问题转化为分类或者回归问题，再用现有的分类、回归方法进行实现。</li>
<li>成对方法(Pairwise Approach)，所谓的pair就是成对的进行排序，比如有一对元素(a,b)，pairwise的方法通过比较成对的元素进行排序。</li>
<li>列表方法(Listwise Approach)，它在学习和预测的过程中都将排序列表作为一个样本，排序的结构被保持</li>
</ol>
<p>BPR属于成对方法(Pairwise Approach)。</p>
<h2 id="bpr建模思路">BPR建模思路</h2>
<p>如下图所示，这是一个隐式反馈矩阵：</p>
<img src="/2022/09/BPR/1.png" class="">
<p>其中+代表用户对对应的商品产生了交互，?代表没有产生交互。</p>
<p>记用户为<span class="math inline">\(u\)</span>，物品为<span class="math inline">\(i,j\)</span>，当物品<span class="math inline">\(i,j\)</span>同时存在时，用户<span class="math inline">\(u\)</span>选择(点击、收藏等隐式操作)了<span class="math inline">\(i\)</span>，那么就得到了三元组<span class="math inline">\((u,i,j)\)</span>，它表示对于用户<span class="math inline">\(u\)</span>来说，物品<span class="math inline">\(i\)</span>排在<span class="math inline">\(j\)</span>的前面。</p>
<p>为了方便表述，将三元组<span class="math inline">\((u,i,j)\)</span>表示为<span class="math inline">\(i&gt;_{u}j\)</span>, 有了这样的假设我们可以将用户-物品隐式反馈矩阵拆分成每个用户各自的物品排序矩阵： <img src="/2022/09/BPR/2.png" class=""></p>
<p>基于贝叶斯理论自然少不了独立性的假设，在BPR中有两个假设：</p>
<ol type="1">
<li>每个用户之间的偏好行为相互独立，即用户在<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>中的偏好与其他用户无关。</li>
<li>同一用户对不同物品的偏序相互独立，也就是用户<span class="math inline">\(u\)</span>在商品<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>之间的偏好和其他的商品无关</li>
</ol>
<p>在BPR中，这个排序关系符号<span class="math inline">\(&gt;_{u}\)</span>满足完全性，反对称性和传递性，即对于用户集<span class="math inline">\(U\)</span>和物品集<span class="math inline">\(I\)</span>：</p>
<ol type="1">
<li>完整性: <span class="math inline">\(\forall i,j \in I: i \neq j \Rightarrow i &gt;_{u}j \cup j&gt;_{u}i\)</span></li>
<li>反对称性：<span class="math inline">\(\forall i,j \in I: i&gt;_{u}j \cap j&gt;_{u}i \Rightarrow i=j\)</span></li>
<li>传递性：<span class="math inline">\(\forall i,j \in I: i&gt;_{u}j \cap j&gt;_{u}k \Rightarrow i&gt;_{u}k\)</span></li>
</ol>
<p>BPR使用了矩阵分解方法来得到预测排序矩阵<span class="math inline">\(\hat{X}\)</span>:</p>
<p><span class="math display">\[
\hat{X} = WH^T
\]</span></p>
<p>其中<span class="math inline">\(W^{|U| \times K}\)</span>为用户矩阵，<span class="math inline">\(H^{|I| \times K}\)</span>为物品矩阵，由于BPR是基于用户维度的，所以对于任意一个用户u，对应的任意一个物品<span class="math inline">\(i\)</span>其期望为：</p>
<p><span class="math display">\[
\hat{x}_{ui} = w_u h_i = \sum_{j=1}^{k}w_{uj}h_{ij}
\]</span></p>
<p>其中<span class="math inline">\(\hat{x}_{ui}\)</span>表示物品<span class="math inline">\(i\)</span>对于用户<span class="math inline">\(u\)</span>的排序优先度。</p>
<h2 id="bpr的算法优化思路">BPR的算法优化思路</h2>
<p>BPR基于最大后验估计<span class="math inline">\(P(W,H|&gt;_{u})\)</span>来求解模型参数<span class="math inline">\(W\)</span>和<span class="math inline">\(H\)</span>，用<span class="math inline">\(\theta\)</span>来表示参数<span class="math inline">\(W\)</span>和<span class="math inline">\(H\)</span>，根据贝叶斯公式得到我们的优化目标：</p>
<p><span class="math display">\[
P(\theta|&gt;_{u}) = \frac{P(&gt;_{u}|\theta)P(\theta)}{P(&gt;_{u})}
\]</span></p>
<p>其中<span class="math inline">\(&gt;_{u}\)</span>代表用户<span class="math inline">\(u\)</span>对应的所有商品的全序关系，由于全序关系已经确定，进一步来说可以得到:</p>
<p><span class="math display">\[
P(\theta|&gt;_u) \propto P(&gt;_u|\theta)P(\theta)
\]</span></p>
<p>这个优化目标转化为了两个部分，其中第一部分与数据集<span class="math inline">\(D\)</span>有关，第二部分无关。</p>
<p>对于第一部分，由于我们假设每个用户之间的偏好行为相互独立，同一用户对不同物品的偏序相互独立，所以有：</p>
<p><span class="math display">\[
\prod_{u \in U}P(&gt;_u|\theta) = \prod_{(u,i,j) \in (U \times I \times I)}P(i &gt;_u j|\theta)^{\delta((u,i,j) \in D)}(1-P(i &gt;_u j|\theta))^{\delta((u,i,j) \not\in D) }
\]</span></p>
<p>其中 <span class="math display">\[
\delta(b)= \begin{cases} 1&amp; {if\; b\; is \;true}\\ 0&amp; {else} \end{cases}
\]</span></p>
<p>根据完整性和反对称性，<span class="math inline">\((u,i,j) \in (U \times I \times I)\)</span>, <span class="math inline">\(P(i &gt;_u j|\theta)^{\delta((u,i,j) \in D)}\)</span>和<span class="math inline">\((1-P(i &gt;_u j|\theta))^{\delta((u,j,i) \not\in D) }\)</span>提供了相同的信息，那么在最大似然里只需要一个即可，第一部分可以简化为：</p>
<p><span class="math display">\[
\prod_{(u,i,j) \in D}P(i &gt;_u j|\theta)
\]</span></p>
<p>对于<span class="math inline">\(P(i&gt;_{u}j|\theta)\)</span>这个概率我们将其替换为： <span class="math display">\[
\sigma(\hat{x}_{uij}(\theta))
\]</span></p>
<p>其中<span class="math inline">\(\sigma(\cdot)\)</span>是sigmoid函数，由于<span class="math inline">\(\sigma(\cdot)\)</span>有函数性质：</p>
<p><span class="math display">\[
0.5 \leq \sigma(x) &lt; 1 \quad \textbf{if} \quad x&gt;0\\
0 &lt; \sigma(x) \leq 0.5 \quad \textbf{if} \quad x\leq0
\]</span></p>
<p>需要满足：</p>
<p><span class="math display">\[
\hat{x}_{uij}(\theta) &gt; 0 \quad \textbf{if} \quad i&gt;_{u}j \\
\hat{x}_{uij}(\theta) &lt; 0 \quad \textbf{if} \quad j&gt;_{u}i
\]</span></p>
<p>因此我们可以设令<span class="math inline">\(\hat{x}_{uij} = \hat{x}_{ui} - \hat{x}_{uj}\)</span>，最终我们第一部分的优化目标从<span class="math inline">\(\prod_{u \in U}P(&gt;_u|\theta)\)</span>转化为：</p>
<p><span class="math display">\[
\prod_{(u,i,j) \in D} \sigma(\overline{x}_{ui} - \overline{x}_{uj})
\]</span></p>
<p>对于第二部分<span class="math inline">\(P(\theta)\)</span>，论文作者直接假设这个概率符合正态分布，且对应均值为0，协方差矩阵是<span class="math inline">\(\lambda_{\theta}I\)</span>，即：</p>
<p><span class="math display">\[
P(\theta) \sim N(0, \lambda_{\theta}I)
\]</span></p>
<p>对于以上这个假设的多位正态分布，其对数和<span class="math inline">\(||\theta||^{2}\)</span>成正比，即：</p>
<p><span class="math display">\[
\ln P(\theta) = \lambda ||\theta||^{2} 
\]</span></p>
<p>最后得到对数后验估计函数： <span class="math display">\[
\begin{align*}
    \ln P(&gt;_u|\theta)P(\theta) &amp;= \ln \prod\limits_{(u,i,j) \in D} \sigma(\overline{x}_{ui} - \overline{x}_{uj}) + \ln P(\theta)\\ &amp;= \sum\limits_{(u,i,j) \in D}ln\sigma(\overline{x}_{ui} - \overline{x}_{uj}) + \lambda||\theta||^2\;
\end{align*}
\]</span></p>
<p>最后使用梯度下降或者牛顿法等优化方法来求解模型参数即可。</p>
<h2 id="bpr-loss">BPR Loss</h2>
<p>将BPR的思想拓展到损失函数上，就得到了BPR Loss，它的思想就是让正样本和负样本之间的分差尽可能大，具体公式如下： <span class="math display">\[
L_{BPR} = -\frac{1}{N_{s}}\sum_{j=1}^{N_s}\log \sigma(r_i - r_j) 
\]</span></p>
<h2 id="参考">参考</h2>
<ol type="1">
<li><a href="https://www.cnblogs.com/pinard/p/9128682.html">博客园 - 贝叶斯个性化排序(BPR)算法小结</a></li>
<li><a href="https://blog.csdn.net/qq_35541614/article/details/103816504">CSDN - BPR Loss</a></li>
<li><a href="https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf">arxiv - BPR: Bayesian Personalized Ranking from Implicit Feedback</a></li>
</ol>
]]></content>
      <tags>
        <tag>推荐系统</tag>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title>归一化折损累计增益NDCG</title>
    <url>/2022/09/NDGC/</url>
    <content><![CDATA[<p>归一化折损累计增益(<em>NDCG, Normalized Discounted Cumulative Gain</em>)是一种针对排序的评价指标，用于评价排序的准确性。在推荐系统中通常为某用户返回一个物品列表，假设列表长度为<span class="math inline">\(K\)</span>，这时可以用<span class="math inline">\(NDCG@K\)</span>评价该排序列表与用户真实交互列表的差距。 <span id="more"></span></p>
<h2 id="计算">计算</h2>
<h3 id="累计增益cg">累计增益CG</h3>
<p><span class="math display">\[
CG_{K} = \sum_{i=1}^{K}r_{i}
\]</span></p>
<p><span class="math inline">\(CG_K\)</span>(<span class="math inline">\(CG@K\)</span>)是推荐列表中所有物品的相关性综合，<span class="math inline">\(r\)</span>表示相似性分数，对应数据集中的打分，比如在显式的打分数据集中，分数取值就是<span class="math inline">\(r \in [0,5]\)</span>，而在隐式数据集中打分的取值就是<span class="math inline">\(r \in \{0,1\}\)</span>。</p>
<h3 id="折损累计增益dcg">折损累计增益DCG</h3>
<p>DCG在CG的基础上提出了在推荐列表的靠后的位置出现了相关性排名较高的物品时，应该对评分给予惩罚。</p>
<p><span class="math display">\[
DCG_K = \sum_{i=1}^{k} \frac{r_i}{\log{(i+1)}}
\]</span></p>
<p>还有一种比较常用的公式：</p>
<p><span class="math display">\[
DCG_K = \sum_{i=1}^{K} \frac{2^{r_i}-1}{\log{(i+1)}}
\]</span></p>
<p>后一个公式在工业中被广泛使用，如多数的搜索公司和 Kaggle 等数据科学竞赛平台等</p>
<p>当相关性得分<span class="math inline">\(r \in \{0,1\}\)</span>时，上述两个公式等价。</p>
<h2 id="归一化折损累计增益ndcg">归一化折损累计增益nDCG</h2>
<p><span class="math display">\[
nDCG_k = \frac{DCG_k}{iDCG_k}
\]</span></p>
<p><span class="math inline">\(iDCG_k\)</span>时最大累计增益，其计算方法是将所有的物品根据真实数据集上的分数进行排序，然后取前<span class="math inline">\(K\)</span>个进行计算<span class="math inline">\(DCG\)</span>所能得到的最大分数。</p>
<p><span class="math display">\[
IDCG_K = \sum_{i=1}^{|REL_K|} \frac{r_i}{\log(i+1)}
\]</span></p>
<p>其中<span class="math inline">\(REL_K\)</span>代表按相关性从高到低的真实列表中取前<span class="math inline">\(K\)</span>个物品</p>
<h2 id="参考">参考</h2>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/136199536">知乎 - Ranking算法评测指标之CG、DCG、NDCG</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/366760688">知乎 - 推荐系统评价指标nDCG到底如何实现</a></li>
</ol>
]]></content>
      <tags>
        <tag>推荐系统</tag>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch复现</title>
    <url>/2022/09/PyTorch%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<p>通过一些设置我们可以让基于PyTorch的实验结果是可复现的</p>
<span id="more"></span>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">same_seed</span>(<span class="params">seed</span>): </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Fixes random number generator seeds for reproducibility.&#x27;&#x27;&#x27;</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>当<code>torch.backends.cudnn.deterministic</code>为<code>True</code>时，cuDNN只使用确定性的卷积算法。</li>
<li>当<code>torch.backends.cudnn.benchmark</code>为<code>True</code>时，会让cuDNN对多个卷积算法进行基准测试，从中选出最快的。</li>
<li><code>np.random.seed()</code>, <code>torch.manual_seed()</code>, <code>torch.cuda.manual_seed_all()</code>都是在对种子进行设置，需要注意的是，如果要使用GPU加速，那么cuda需要单独设置种子。</li>
<li>cuDNN(CUDA Deep Neural Network)是由<strong>Nvidia</strong>提供的用于深度神经网络构建的GPU加速库。</li>
<li>torch.backends这个库包含了PyTorch的各种后端行为控制。</li>
</ol>
<h2 id="数据集划分">数据集划分</h2>
<p>数据集划分的时候我们也希望能够设定随机种子：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> random_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_valid_split</span>(<span class="params">data_set, valid_ratio, seed</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Split provided training data into training set and validation set&#x27;&#x27;&#x27;</span></span><br><span class="line">    valid_set_size = <span class="built_in">int</span>(valid_ratio * <span class="built_in">len</span>(data_set)) </span><br><span class="line">    train_set_size = <span class="built_in">len</span>(data_set) - valid_set_size</span><br><span class="line">    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))</span><br><span class="line">    <span class="keyword">return</span> np.array(train_set), np.array(valid_set)</span><br></pre></td></tr></table></figure>
<p><code>random_split()</code>中的<code>generator</code>参数是用于随机排列的生成器，使用一样的seed就能保证，每次划分的结果一致。</p>
<h3 id="class-torch.generator">class torch.Generator()</h3>
<p>Generator类会返回一个对象，用于管理伪随机数的生成。</p>
]]></content>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch数据集构建</title>
    <url>/2022/09/PyTorch%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<p>在Pytorch中，训练和验证过程一般都要用到<code>DataLoader</code>类来装载数据集，它会返回一个可迭代对象用于训练和验证。<code>DataLoader</code>需要的对象是<code>Data</code>类型，定义方法如下：</p>
<span id="more"></span>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    x: Features.</span></span><br><span class="line"><span class="string">    y: Targets, if none, do prediction.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.y = y</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.y = torch.FloatTensor(y)</span><br><span class="line">        self.x = torch.FloatTensor(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">if</span> self.y <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> self.x[idx]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.x[idx], self.y[idx]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.x)</span><br></pre></td></tr></table></figure>
<p>其中<code>__getitem__</code>和<code>__len__</code>是必须要实现的，对于可以以顺序表存储的数据都可以使用以上方式存储。而对于难以随机读取或者开销过大的数据(例如从数据库、远程服务器中读取数据)，可以用<code>IterableDataset</code>。</p>
]]></content>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
</search>
